{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot CNN Obstacle Detection — Colab Test Notebook\n",
    "\n",
    "This notebook tests the CNN obstacle avoidance environment on Google Colab.\n",
    "\n",
    "**Steps:**\n",
    "1. Install dependencies & configure headless MuJoCo\n",
    "2. Smoke test: environment loads and steps\n",
    "3. Verify CNN feature extractor builds\n",
    "4. Short training run (sanity check)\n",
    "5. Visualise camera output from the robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies & Setup Headless Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system-level EGL libs for headless MuJoCo rendering\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq libegl1-mesa-dev libgl1-mesa-dev libgles2-mesa-dev libglfw3-dev > /dev/null 2>&1\n",
    "\n",
    "# Install Python packages\n",
    "!pip install -q gymnasium>=0.29.0 mujoco>=3.0.0 numpy>=1.24.0\n",
    "!pip install -q \"stable-baselines3[extra]>=2.2.0\" tensorboard>=2.14.0\n",
    "!pip install -q torch>=2.0.0 torchvision>=0.15.0\n",
    "!pip install -q matplotlib>=3.7.0 imageio>=2.31.0\n",
    "\n",
    "print(\"\\nDependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure MuJoCo to use EGL for offscreen rendering (no display needed)\n",
    "import os\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "\n",
    "# Verify MuJoCo + EGL works\n",
    "import mujoco\n",
    "print(f\"MuJoCo version: {mujoco.__version__}\")\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(\"\\nAll imports OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload / Clone Project Files\n",
    "\n",
    "**Option A** — Clone the repo (recommended):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Clone from GitHub (update URL to your repo)\n",
    "# !git clone https://github.com/Raj9408612613/claude_code.git\n",
    "# %cd claude_code/files\n",
    "\n",
    "# Option B: If you uploaded the files manually to Colab, set the path:\n",
    "# %cd /content/files\n",
    "\n",
    "# For now, let's assume files are in the current directory.\n",
    "# Uncomment one of the options above and run this cell.\n",
    "print(\"Set your working directory above, then re-run this cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify project files are present\n",
    "required_files = [\n",
    "    \"spot_scene.xml\",\n",
    "    \"spot_obstacle_env.py\",\n",
    "    \"cnn_policy.py\",\n",
    "    \"train_obstacle.py\",\n",
    "    \"config.py\",\n",
    "]\n",
    "for f in required_files:\n",
    "    exists = os.path.exists(f)\n",
    "    status = \"OK\" if exists else \"MISSING\"\n",
    "    print(f\"  [{status}] {f}\")\n",
    "    if not exists:\n",
    "        raise FileNotFoundError(f\"{f} not found — check your working directory (pwd: {os.getcwd()})\")\n",
    "\n",
    "print(\"\\nAll files present!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Smoke Test — Environment Loads and Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spot_obstacle_env import SpotObstacleEnv\n",
    "\n",
    "# Create environment (no display needed — rendering is offscreen via EGL)\n",
    "env = SpotObstacleEnv(render_mode=None, camera_width=64, camera_height=64, n_obstacles_active=5)\n",
    "obs, info = env.reset(seed=42)\n",
    "\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "print(\"Action space:    \", env.action_space)\n",
    "print()\n",
    "print(f\"Image shape:          {obs['image'].shape}  dtype={obs['image'].dtype}\")\n",
    "print(f\"Proprioception shape: {obs['proprioception'].shape}  dtype={obs['proprioception'].dtype}\")\n",
    "print(f\"Info: {info}\")\n",
    "print()\n",
    "\n",
    "# Run 20 random steps\n",
    "for i in range(20):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    print(f\"Step {i:2d}: reward={reward:+.3f}  min_obs_dist={info['min_obstacle_dist']:.2f}  \"\n",
    "          f\"collisions={info['obstacle_collisions']}\")\n",
    "    if terminated or truncated:\n",
    "        print(\"         -> Episode ended, resetting.\")\n",
    "        obs, info = env.reset()\n",
    "\n",
    "env.close()\n",
    "print(\"\\nSmoke test PASSED!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualise Camera Output\n",
    "\n",
    "Show what the robot's front camera actually sees — obstacles should appear as red shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = SpotObstacleEnv(camera_width=128, camera_height=128, n_obstacles_active=5)\n",
    "obs, info = env.reset(seed=7)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "fig.suptitle(\"Front Camera View (4 random resets)\", fontsize=14)\n",
    "\n",
    "for idx in range(4):\n",
    "    obs, info = env.reset(seed=idx * 10)\n",
    "    # Take a few steps so the robot is moving\n",
    "    for _ in range(5):\n",
    "        obs, _, _, _, info = env.step(env.action_space.sample())\n",
    "    \n",
    "    axes[idx].imshow(obs[\"image\"])\n",
    "    axes[idx].set_title(f\"Seed {idx*10}\\ndist_to_goal={info['distance_to_goal']:.1f}m\")\n",
    "    axes[idx].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "env.close()\n",
    "print(\"Camera visualisation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify CNN Feature Extractor Builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_policy import SpotCNNExtractor\n",
    "from stable_baselines3 import PPO\n",
    "import torch as th\n",
    "\n",
    "env = SpotObstacleEnv(camera_width=64, camera_height=64)\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=SpotCNNExtractor,\n",
    "    features_extractor_kwargs=dict(cnn_output_dim=128, proprio_hidden_dim=64),\n",
    "    net_arch=dict(pi=[256, 128], vf=[256, 128]),\n",
    "    activation_fn=th.nn.ReLU,\n",
    ")\n",
    "\n",
    "model = PPO(\"MultiInputPolicy\", env, policy_kwargs=policy_kwargs, verbose=0)\n",
    "\n",
    "print(\"PPO + CNN model created successfully!\")\n",
    "print()\n",
    "print(\"Feature extractor:\")\n",
    "print(model.policy.features_extractor)\n",
    "print()\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.policy.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.policy.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters:     {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "env.close()\n",
    "print(\"\\nCNN extractor test PASSED!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Short Training Run (Sanity Check)\n",
    "\n",
    "Run a quick 5k-step training to verify the full loop works (rollouts, gradient updates, logging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "def make_env(seed=0):\n",
    "    def _init():\n",
    "        e = SpotObstacleEnv(camera_width=64, camera_height=64, n_obstacles_active=5)\n",
    "        e.reset(seed=seed)\n",
    "        return Monitor(e)\n",
    "    return _init\n",
    "\n",
    "train_env = DummyVecEnv([make_env(seed=0)])\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=SpotCNNExtractor,\n",
    "    features_extractor_kwargs=dict(cnn_output_dim=128, proprio_hidden_dim=64),\n",
    "    net_arch=dict(pi=[256, 128], vf=[256, 128]),\n",
    "    activation_fn=th.nn.ReLU,\n",
    ")\n",
    "\n",
    "model = PPO(\n",
    "    \"MultiInputPolicy\",\n",
    "    train_env,\n",
    "    learning_rate=3e-4,\n",
    "    n_steps=512,       # smaller for quick test\n",
    "    batch_size=64,\n",
    "    n_epochs=4,        # fewer epochs for quick test\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    ent_coef=0.01,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"Training for 5,000 steps (quick sanity check)...\")\n",
    "model.learn(total_timesteps=5_000, progress_bar=True)\n",
    "\n",
    "train_env.close()\n",
    "print(\"\\nShort training run PASSED!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Full Training (Optional)\n",
    "\n",
    "Launch a proper training run. On a Colab T4 GPU, ~500k steps may take 1-2 hours.\n",
    "Adjust `--timesteps` based on your available runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run full training:\n",
    "# !python train_obstacle.py --timesteps 500000 --n_envs 1 --camera_size 64 --n_obstacles 5\n",
    "\n",
    "print(\"Uncomment the line above and run this cell to start full training.\")\n",
    "print(\"Monitor with TensorBoard:\")\n",
    "print(\"  %load_ext tensorboard\")\n",
    "print(\"  %tensorboard --logdir spot_obstacle_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard inline (run after training starts)\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir spot_obstacle_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "If all cells above ran without errors, the CNN obstacle detection pipeline is working.\n",
    "\n",
    "**Summary of what was tested:**\n",
    "1. MuJoCo + EGL headless rendering\n",
    "2. SpotObstacleEnv: Dict obs (image + proprioception), obstacle placement, collision detection\n",
    "3. Camera output visualisation\n",
    "4. SpotCNNExtractor: Nature-CNN + proprioception MLP\n",
    "5. PPO training loop with MultiInputPolicy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
